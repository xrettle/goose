"use strict";(self.webpackChunkgoose=self.webpackChunkgoose||[]).push([[7028],{96599:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>p,frontMatter:()=>a,metadata:()=>o,toc:()=>c});var o=n(58288),s=n(74848),i=n(28453);const a={title:"Automated MCP Testing: Using Composable Goose Recipes to Validate Tool Metadata",description:"Automate MCP tool metadata validation using composable Goose recipes to catch regressions, optimize token usage, and ensure AI agents can reliably discover and use your tools.",authors:["rarora"]},r="Automated MCP Testing: Using Composable Goose Recipes to Validate Tool Metadata",l={authorsImageUrls:[void 0]},c=[{value:"1. The Challenges of Manual Metadata Testing",id:"1-the-challenges-of-manual-metadata-testing",level:2},{value:"Key Limitations:",id:"key-limitations",level:4},{value:"2. System Overview: Modular and Composable Goose Recipes",id:"2-system-overview-modular-and-composable-goose-recipes",level:2},{value:"3. The Core Engine: Goose Recipe for Tool Prediction",id:"3-the-core-engine-goose-recipe-for-tool-prediction",level:2},{value:"\ud83d\udd04 How It Works: Step-by-Step",id:"-how-it-works-step-by-step",level:4},{value:"\ud83d\udd27 Complete Recipe Specification",id:"-complete-recipe-specification",level:4},{value:"\ud83d\ude80 Running the Recipe",id:"-running-the-recipe",level:4},{value:"\ud83e\uddea Example Output JSON",id:"-example-output-json",level:4},{value:"4. Workflow 1: Automated Metadata Regression Detection",id:"4-workflow-1-automated-metadata-regression-detection",level:2},{value:"\ud83d\udd04 How It Works: Step-by-Step",id:"-how-it-works-step-by-step-1",level:4},{value:"\ud83e\uddea Complete Evaluation Recipe",id:"-complete-evaluation-recipe",level:4},{value:"\ud83d\ude80 Running the Complete Evaluation",id:"-running-the-complete-evaluation",level:4},{value:"\ud83d\udcc9 Example Comparison Results",id:"-example-comparison-results",level:4},{value:"\ud83d\udd0d What Gets Flagged vs. Ignored",id:"-what-gets-flagged-vs-ignored",level:4},{value:"5. Workflow 2: Safe Metadata Token Reduction and Optimization",id:"5-workflow-2-safe-metadata-token-reduction-and-optimization",level:2},{value:"\ud83d\udd04 The Optimization Loop: Step-by-Step",id:"-the-optimization-loop-step-by-step",level:4},{value:"\ud83e\uddea Complete Token Reduction Recipe",id:"-complete-token-reduction-recipe",level:4},{value:"\ud83d\ude80 Running the Token Reduction Loop",id:"-running-the-token-reduction-loop",level:4},{value:"\ud83d\udcc9 Real Example: Iterative Fixing Process",id:"-real-example-iterative-fixing-process",level:4},{value:"\ud83c\udfaf Real Results Summary",id:"-real-results-summary",level:4},{value:"6. Conclusion",id:"6-conclusion",level:2}];function d(e){const t={a:"a",blockquote:"blockquote",code:"code",h2:"h2",h4:"h4",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components},{Details:o,Head:a}=t;return o||u("Details",!0),a||u("Head",!0),(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"Automated MCP Testing",src:n(35151).A+"",width:"1472",height:"832"})}),"\n",(0,s.jsx)(t.p,{children:'When building Model Context Protocol (MCP) servers, most development focuses on tool functionality, ensuring tools execute and return expected results. But just as critical is the quality of tool metadata: descriptions, tooltips, and input schemas. These elements form the "interface language" between tools and AI agents like Goose.'}),"\n",(0,s.jsxs)(t.p,{children:["Yet metadata often goes untested. This can break tool discovery and silently degrade agent behavior. In this post, we\u2019ll show how to automate metadata validation using ",(0,s.jsx)(t.strong,{children:"composable Goose recipes"}),", turning manual QA into modular, repeatable workflows that:"]}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Validate tool discoverability and parameter accuracy"}),"\n",(0,s.jsx)(t.li,{children:"Detect regressions early"}),"\n",(0,s.jsx)(t.li,{children:"Safely reduce token usage"}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"All while maintaining the quality that AI agents depend on."}),"\n",(0,s.jsx)(t.h2,{id:"1-the-challenges-of-manual-metadata-testing",children:"1. The Challenges of Manual Metadata Testing"}),"\n",(0,s.jsx)(t.p,{children:"Manually validating MCP metadata\u2014by running queries and inspecting agent behavior\u2014breaks down quickly as your toolset grows. It\u2019s inefficient, inconsistent, and prone to silent regressions."}),"\n",(0,s.jsx)(t.h4,{id:"key-limitations",children:"Key Limitations:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Slow & Unscalable"}),": Requires spinning up the agent, entering queries, and reviewing outputs by hand."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Inconsistent Results"}),": Varies across environments and models, making issues hard to reproduce."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Silent Failures"}),": Broken tooltips lead to incorrect tool selection, missing or misinterpreted parameters, and tool conflicts."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"No Regression Safety Net"}),": Changes in one tool\u2019s metadata can affect others with no system in place to detect it."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Poor Coverage"}),": Manual QA can\u2019t account for the diversity of real-world user queries."]}),"\n"]}),"\n",(0,s.jsxs)(t.p,{children:["To keep pace with growing MCP complexity, ",(0,s.jsx)(t.strong,{children:"automated metadata validation becomes a practical necessity"}),"."]}),"\n",(0,s.jsx)(t.h2,{id:"2-system-overview-modular-and-composable-goose-recipes",children:"2. System Overview: Modular and Composable Goose Recipes"}),"\n",(0,s.jsxs)(t.p,{children:["The foundation of this framework is ",(0,s.jsx)(t.a,{href:"https://block.github.io/goose/docs/guides/recipes/",children:"Goose\u2019s recipe engine"}),". Recipes define reusable, declarative workflows for AI-assisted tasks. Each one encapsulates a step\u2014like generating predictions or comparing results\u2014and can be composed into larger pipelines."]}),"\n",(0,s.jsx)(t.p,{children:"We start with a core recipe that maps natural language queries to tool calls. It reads queries, analyzes the toolset, and produces structured JSON mappings. This recipe becomes the building block for workflows like:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Evaluating predictions against a gold set"}),"\n",(0,s.jsx)(t.li,{children:"Integrating regression checks into CI"}),"\n",(0,s.jsx)(t.li,{children:"Running token optimization loops"}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"By chaining and wrapping recipes, we avoid duplication and unlock scalable, repeatable QA for MCP tool discoverability."}),"\n",(0,s.jsx)(t.h2,{id:"3-the-core-engine-goose-recipe-for-tool-prediction",children:"3. The Core Engine: Goose Recipe for Tool Prediction"}),"\n",(0,s.jsx)(t.p,{children:"At the heart of the system is a Goose recipe that systematically transforms natural language queries into structured tool predictions. This recipe follows a clear three-step process:"}),"\n",(0,s.jsxs)(t.blockquote,{children:["\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"read queries \u2192 analyze tools \u2192 generate predictions"})}),"\n"]}),"\n",(0,s.jsx)(t.h4,{id:"-how-it-works-step-by-step",children:"\ud83d\udd04 How It Works: Step-by-Step"}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Step 1: Read Queries"}),"\nThe recipe starts by reading a plain text file containing natural language queries, one per line:"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{children:"List contributors to the block/mcp repository\nList the top 10 contributors to block/goose\nShow me the closed branches in block/mcp\nShow me all branches in the block/goose repository\n"})}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Step 2: Ask Goose to Make Predictions"}),"\nUsing the developer extension, Goose analyzes the MCP server source code and documentation to understand available tools, their parameters, and usage patterns. It then maps each query to the most appropriate tool call."]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Step 3: Write Predictions to JSON"}),"\nThe output is a structured JSON file with each query mapped to its expected tool and parameters."]}),"\n",(0,s.jsx)(t.h4,{id:"-complete-recipe-specification",children:"\ud83d\udd27 Complete Recipe Specification"}),"\n",(0,s.jsxs)(o,{children:[(0,s.jsx)("summary",{children:"Click to expand full recipe YAML"}),(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-yaml",children:'version: 1.0.0\ntitle: Generate tool predictions for natural language query\ndescription: Generate a dataset for MCP tools that maps natural language queries to their expected tool calls\ninstructions: |\n  Generate evaluation datasets that map natural language queries to their expected tool calls with parameters. Analyze tool documentation and source code to understand available functions, their parameters, and usage patterns. Create comprehensive JSON test cases that include the original query, expected tool name, and all required/implied parameters with realistic values. The output should be a complete JSON file with test_cases array, where each case maps a natural language request to its corresponding structured tool call. Use developer tools to examine source files, read documentation, and write the final JSON dataset to disk.\n    For each query, provide\n    - The natural language query\n    - The expected tool name\n    - All required parameters with appropriate values\n    - Any optional parameters that are clearly implied by the query\n\n    Tools documentation: {{ server_input }}, {{ tool_documentation }}\n\n    Please generate a JSON file mapping queries to their expected tool calls with parameters.\n\n    {\n        "test_cases": [\n            {\n                "query": "Show me open pull requests in the block/goose repository",\n                "expected": {\n                    "tool": "tool_name",\n                    "parameters": {\n                        "repo_owner": "block",\n                        "repo_name": "goose",\n                        "p1": "test",\n                        "p2": "test"\n                    }\n                }\n            },\n            {\n                "query": "Create a new issue titled \'Update documentation\' in the mcp repo",\n                "expected": {\n                    "tool": "tool_name",\n                    "parameters": {\n                        "repo_owner": "block",\n                        "repo_name": "mcp",\n                        "p1": "test",\n                        "p2": "test"\n                    }\n                }\n            }\n        ]\n    }\n\n    Query Input - {{ quey_input }}\n    Output File - {{ output_file }}\nprompt: Generate evaluation datasets that map natural language queries to their expected tool calls with parameters. Analyze tool documentation and source code to understand available functions, their parameters, and usage patterns. Create comprehensive JSON test cases that include the original query, expected tool name, and all required/implied parameters with realistic values. The output should be a complete JSON file with test_cases array, where each case maps a natural language request to its corresponding structured tool call. Use developer tools to examine source files, read documentation, and write the final JSON dataset to disk. Read instructions for more details.\n\nextensions:\n- type: builtin\n  name: developer\n  display_name: Developer\n  timeout: 300\n  bundled: true\nsettings:\n  goose_provider: databricks\n  goose_model: goose-claude-4-sonnet\n  temperature: 0.0\nparameters:\n- key: server_input\n  input_type: string\n  requirement: required\n  description: server.py file path\n  default: src/mcp_github/server.py\n- key: tool_documentation\n  input_type: string\n  requirement: optional\n  description: Tool documentation\n  default: src/mcp_github/docs/tools.md\n- key: quey_input\n  input_type: string\n  requirement: required\n  description: Input query set\n  default: mcp_github_query_test.txt\n- key: output_file\n  input_type: string\n  requirement: optional\n  description: Output JSON file\n  default: new_evaluation.json\nactivities:\n- Map queries to tool calls\n- Extract tool parameters\n- Generate test datasets\n- Analyze API documentation\n- Create evaluation benchmarks\nauthor:\n  contact: user\n'})})]}),"\n",(0,s.jsx)(t.h4,{id:"-running-the-recipe",children:"\ud83d\ude80 Running the Recipe"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-bash",children:"goose run --recipe generate_predictions_recipe.yaml --params output_file=my_predictions.json\n"})}),"\n",(0,s.jsx)(t.h4,{id:"-example-output-json",children:"\ud83e\uddea Example Output JSON"}),"\n",(0,s.jsx)(t.p,{children:"The recipe generates a comprehensive JSON file mapping each query to its predicted tool call:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-json",children:'{\n  "test_cases": [\n    {\n      "query": "List contributors to the block/mcp repository",\n      "expected": {\n        "tool": "list_repo_contributors",\n        "parameters": {\n          "repo_owner": "block",\n          "repo_name": "mcp"\n        }\n      }\n    },\n    {\n      "query": "Show me the closed branches in block/mcp",\n      "expected": {\n        "tool": "list_branches",\n        "parameters": {\n          "repo_owner": "block",\n          "repo_name": "mcp",\n          "branch_status": "closed"\n        }\n      }\n    },\n    {\n      "query": "Search for files containing console.log",\n      "expected": {\n        "tool": "search_codebase",\n        "parameters": {\n          "search_term": "console.log"\n        }\n      }\n    },\n    {\n      "query": "Find me all the files that are handling nullpointerexception",\n      "expected": {\n        "tool": "search_codebase",\n        "parameters": {\n          "search_term": "nullpointerexception"\n        }\n      }\n    }\n  ]\n}\n'})}),"\n",(0,s.jsx)(t.p,{children:"This JSON becomes the foundation for all downstream evaluation workflows\u2014it captures exactly how Goose interprets each query given the current tool metadata, creating a baseline for detecting future regressions."}),"\n",(0,s.jsx)(t.h2,{id:"4-workflow-1-automated-metadata-regression-detection",children:"4. Workflow 1: Automated Metadata Regression Detection"}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"Automated Metadata Regression Detection",src:n(38351).A+"",width:"3139",height:"416"})}),"\n",(0,s.jsx)(t.p,{children:"Having established the core Goose recipe component in Section 3, we can now leverage its modularity to build more complex workflows. The beauty of this architecture is that the core prediction recipe becomes a reusable building block\u2014we can reference it from other recipes, chain it with comparison logic, and compose end-to-end testing pipelines. This demonstrates the power of treating recipes as separate modules that can be orchestrated together for sophisticated automation workflows."}),"\n",(0,s.jsx)(t.p,{children:'Once predictions are generated via the core recipe, the next step is to detect regressions by comparing them against a curated "gold standard" dataset. This automated evaluation follows a clear three-step process:'}),"\n",(0,s.jsxs)(t.blockquote,{children:["\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"generate predictions \u2192 compare with gold set \u2192 interpret results"})}),"\n"]}),"\n",(0,s.jsx)(t.h4,{id:"-how-it-works-step-by-step-1",children:"\ud83d\udd04 How It Works: Step-by-Step"}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Step 1: Generate Predictions Using the Core Recipe"}),"\nFirst, we run the core recipe from Section 3 to generate fresh predictions based on the current tool metadata:"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-bash",children:"goose run --recipe generate_predictions_recipe.yaml --params output_file=new_evaluation.json\n"})}),"\n",(0,s.jsx)(t.p,{children:"This produces a JSON file with current tool predictions."}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Step 2: Compare Predictions with Gold Standard"}),"\nNext, we use a Python comparison script to identify differences between the new predictions and our verified gold standard:"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-bash",children:"python compare_results.py new_evaluation.json mcp_github_query_tool_truth.json\n"})}),"\n",(0,s.jsx)(t.p,{children:"The script performs a structured diff, flagging mismatches in tool names, parameters, or values."}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Step 3: Ask Goose to Interpret Results"}),"\nFinally, Goose analyzes the comparison output and highlights what's not matching, providing human-readable explanations of the differences."]}),"\n",(0,s.jsx)(t.h4,{id:"-complete-evaluation-recipe",children:"\ud83e\uddea Complete Evaluation Recipe"}),"\n",(0,s.jsxs)(o,{children:[(0,s.jsx)("summary",{children:"Click to expand full evaluation recipe YAML"}),(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-yaml",children:"version: 1.0.0\ntitle: Generate predictions and compare with the gold set\ndescription: Generate predictions and evaluate against a known correct output\ninstructions: |\n  This task involves running automated evaluation scripts to generate tool-parameter mappings from natural language queries, then comparing the output against gold standard datasets to identify discrepancies. \n\n  Command to generate output: goose run --recipe generate_predictions_recipe.yaml --params output_file={{ output_file }}\n  Script to compare 2 files: python compare_results.py {{ output_file }} {{ gold_file }}\n\n  Go over the output of the comparison script and highlight what cases differ in terms of tool name or parameters. You can ignore minor mismatches like:\n    - parameter value casing\n    - value not present vs default value present\nprompt: Generate predictions, evaluate and compare with the gold set. Read instructions for more details.\nextensions:\n- type: builtin\n  name: developer\n  display_name: Developer\n  timeout: 300\n  bundled: true\nsettings:\n  goose_provider: databricks\n  goose_model: goose-claude-4-sonnet\n  temperature: 0.0\nparameters:\n- key: output_file\n  input_type: string\n  requirement: required\n  description: Output file path\n  default: new_evaluation.json\n- key: gold_file\n  input_type: string\n  requirement: required\n  description: Gold file path\n  default: mcp_github_query_tool_truth.json\nactivities:\n- Generate evaluation datasets\n- Compare JSON outputs\n- Analyze parameter mismatches\n- Run recipe commands\n- Identify tool mapping errors\nauthor:\n  contact: user\n"})})]}),"\n",(0,s.jsx)(t.h4,{id:"-running-the-complete-evaluation",children:"\ud83d\ude80 Running the Complete Evaluation"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-bash",children:"goose run --recipe evaluate_predictions.yaml --params output_file=new_evaluation.json gold_file=mcp_github_query_tool_truth.json\n"})}),"\n",(0,s.jsx)(t.h4,{id:"-example-comparison-results",children:"\ud83d\udcc9 Example Comparison Results"}),"\n",(0,s.jsx)(t.p,{children:"Here are two common types of mismatches the system detects:"}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"\u274c Example 1: Tool Name Mismatch"})}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Query:"}),' "Show me the closed branches in block/mcp"']}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Gold Standard:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-json",children:'{\n  "tool": "list_branches",\n  "parameters": {\n    "repo_owner": "block",\n    "repo_name": "mcp",\n    "branch_status": "closed"\n  }\n}\n'})}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Current Prediction:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-json",children:'{\n  "tool": "get_repo_branches", \n  "parameters": {\n    "repo_owner": "block",\n    "repo_name": "mcp",\n    "status": "closed"\n  }\n}\n'})}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Issue:"})," Tool name changed from ",(0,s.jsx)(t.code,{children:"list_branches"})," to ",(0,s.jsx)(t.code,{children:"get_repo_branches"}),", likely due to a tooltip or function name update"]}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"\u274c Example 2: Parameter Mismatch"})}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Query:"}),' "Search for files containing console.log in block/goose"']}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Gold Standard:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-json",children:'{\n  "tool": "search_codebase",\n  "parameters": {\n    "search_term": "console.log",\n    "repo_owner": "block",\n    "repo_name": "goose"\n  }\n}\n'})}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Current Prediction:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-json",children:'{\n  "tool": "search_codebase",\n  "parameters": {\n    "search_term": "console.log"\n  }\n}\n'})}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Issue:"})," Missing ",(0,s.jsx)(t.code,{children:"repo_owner"})," and ",(0,s.jsx)(t.code,{children:"repo_name"})," parameters, suggesting the tool description may not clearly indicate these are required when searching within a specific repository"]}),"\n"]}),"\n",(0,s.jsx)(t.h4,{id:"-what-gets-flagged-vs-ignored",children:"\ud83d\udd0d What Gets Flagged vs. Ignored"}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"Critical Issues (Flagged):"})}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Tool name mismatches"}),"\n",(0,s.jsx)(t.li,{children:"Missing required parameters"}),"\n",(0,s.jsx)(t.li,{children:"Incorrect parameter values"}),"\n",(0,s.jsx)(t.li,{children:"Extra unexpected parameters"}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"Minor Issues (Ignored):"})}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["Parameter value casing differences (",(0,s.jsx)(t.code,{children:'"Console.log"'})," vs ",(0,s.jsx)(t.code,{children:'"console.log"'}),")"]}),"\n",(0,s.jsx)(t.li,{children:"Default values present vs. omitted"}),"\n",(0,s.jsx)(t.li,{children:"Parameter order differences"}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"This feedback loop becomes essential for pull request validation\u2014especially when tool descriptions are updated, new tools are added, or existing schemas are modified. The system ensures that metadata changes don't accidentally break tool discoverability for AI agents."}),"\n",(0,s.jsx)(t.h2,{id:"5-workflow-2-safe-metadata-token-reduction-and-optimization",children:"5. Workflow 2: Safe Metadata Token Reduction and Optimization"}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"Safe Metadata Token Reduction and Optimization",src:n(84218).A+"",width:"3004",height:"1114"})}),"\n",(0,s.jsx)(t.p,{children:"Building on the modular recipe architecture established in previous sections, we can create even more sophisticated workflows that combine multiple automation steps. One powerful example is an iterative token reduction pipeline that safely compresses MCP tool descriptions while ensuring functionality remains intact."}),"\n",(0,s.jsx)(t.p,{children:"This workflow demonstrates the true power of composable Goose recipes\u2014we can orchestrate the core prediction recipe from Section 3 and the evaluation workflow from Section 4 into a continuous optimization loop that reduces token usage without breaking tool discoverability."}),"\n",(0,s.jsx)(t.h4,{id:"-the-optimization-loop-step-by-step",children:"\ud83d\udd04 The Optimization Loop: Step-by-Step"}),"\n",(0,s.jsx)(t.p,{children:"The token reduction workflow follows an iterative process:"}),"\n",(0,s.jsxs)(t.blockquote,{children:["\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"reduce tokens \u2192 run evaluation \u2192 fix issues \u2192 run evaluation \u2192 repeat"})}),"\n"]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Step 1: Compress Tool Descriptions"}),"\nUsing natural language processing, Goose identifies verbose tooltips, redundant documentation, and unnecessary examples, then compresses them while preserving essential information."]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Step 2: Run Evaluation Pipeline"}),"\nThe system automatically triggers the evaluation workflow from Section 4 to test whether the compressed descriptions still allow correct tool discovery."]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Step 3: Fix Issues"}),"\nIf evaluation tests fail, Goose analyzes the specific mismatches and iteratively fixes the compressed tooltips to restore functionality."]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Step 4: Repeat Until Success"}),"\nThe loop continues until all evaluation tests pass, ensuring no regressions in tool discoverability."]}),"\n",(0,s.jsx)(t.h4,{id:"-complete-token-reduction-recipe",children:"\ud83e\uddea Complete Token Reduction Recipe"}),"\n",(0,s.jsxs)(o,{children:[(0,s.jsx)("summary",{children:"Click to expand full token reduction recipe YAML"}),(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-yaml",children:"version: 1.0.0\ntitle: Compress MCP token and Evaluate\ndescription: Recipe for running the reduce mcp token and evaluation in a loop\ninstructions: |\n  This task involves optimizing MCP (Model Context Protocol) tool definitions by reducing token count in tooltips, \n  field descriptions, and documentation while maintaining functionality. \n  The process requires creating backups, compressing descriptions and docstrings, removing verbose examples and redundant text, then running evaluation tests to ensure no functionality is broken. \n  If tests fail, iteratively fix the compressed tooltips and re-run evaluations until all tests pass. \n  The goal is to achieve significant token reduction {{ target_reduction }}% while preserving tool accuracy.\n  Use the provided token counting script to measure before/after savings and report final reduction percentages.\n\n  Files containing tokens:\n  MCP server file: {{ server_input }}\n  MCP tool documentation {{ tool_documentation }}\n  Script to count tokens {{ count_token_script }}\n  Command to run evaluation goose run --recipe evaluate_predictions.yaml\nprompt: Reduce token count for tool descriptions and tooltips and make sure evaluation succeeds. Read instructions for more details\nextensions:\n- type: builtin\n  name: developer\n  display_name: Developer\n  timeout: 300\n  bundled: true\nsettings:\n  goose_provider: databricks\n  goose_model: goose-claude-4-sonnet\n  temperature: 0.0\nparameters:\n- key: server_input\n  input_type: string\n  requirement: required\n  description: server.py file path\n  default: src/mcp_github/server.py\n- key: tool_documentation\n  input_type: string\n  requirement: optional\n  description: Tool documentation\n  default: src/mcp_github/docs/tools.md\n- key: count_token_script\n  input_type: string\n  requirement: optional\n  description: Script to count tokens in server files\n  default: count_tooltip_tokens.py\n- key: target_reduction\n  input_type: number\n  requirement: optional\n  description: Target reduction in token count we want to achieve\n  default: 30\nactivities:\n- Compress tool tooltips\n- Remove verbose examples\n- Run evaluation tests\n- Fix failing test cases\n- Calculate token savings\nauthor:\n  contact: rarora\n"})})]}),"\n",(0,s.jsx)(t.h4,{id:"-running-the-token-reduction-loop",children:"\ud83d\ude80 Running the Token Reduction Loop"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-bash",children:"goose run --recipe compress_evaluate_mcp.yaml --params target_reduction=10\n"})}),"\n",(0,s.jsx)(t.h4,{id:"-real-example-iterative-fixing-process",children:"\ud83d\udcc9 Real Example: Iterative Fixing Process"}),"\n",(0,s.jsx)(t.p,{children:"Here's an actual example from running this workflow, showing how the system identifies and fixes issues:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{children:'The evaluation shows that our token compression was successful, but we have some test failures. Let me analyze the specific issues and fix them:\n\n1. Time format differences: "7 days" vs "P1W", "20 days" vs "P20D"\n2. File search time format: absolute timestamp vs "1w"\n3. Minor typos in queries: "branchs" vs "branches", "coomits" vs "commits", "file sin" vs "files in"\n\nLet me fix the time format issue by updating the tooltips to be more specific about expected formats:\n'})}),"\n",(0,s.jsx)(t.p,{children:"The system then automatically updates the tool descriptions and re-runs the evaluation until all tests pass."}),"\n",(0,s.jsx)(t.h4,{id:"-real-results-summary",children:"\ud83c\udfaf Real Results Summary"}),"\n",(0,s.jsx)(t.p,{children:"Here's an actual summary from a successful token reduction run:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{children:'# Summary\n\nI have successfully completed the token reduction task for the GitHub MCP tools. Here\'s a comprehensive summary of what was accomplished:\n\n## \ud83d\udcca Token Reduction Results\n\n**Final Token Savings:**\n- **Original tokens**: 5,819 (2,174 from server.py + 3,645 from tools.md)\n- **After compression**: 1,603 (445 from server.py + 1,158 from tools.md)\n- **Total reduction**: 4,216 tokens\n- **Percentage reduction**: 72.5%\n\n## \ud83c\udfaf Target Achievement\n\nThe task requested a 10% token reduction, but I achieved **72.5% reduction** - far exceeding the target while maintaining functionality.\n\n## \ud83d\udd27 Compression Strategies Applied\n\n### 1. Server.py Optimizations\n- **Field descriptions**: Shortened verbose descriptions (e.g., "Repository owner" \u2192 "Repo owner")\n- **Docstrings**: Compressed from detailed explanations to concise summaries\n- **Parameter hints**: Added specific format hints for time parameters (ISO 8601: P1W, P20D)\n- **Removed redundant words**: Eliminated unnecessary qualifiers and explanations\n\n### 2. Tools.md Optimizations\n- **Removed sections**: Eliminated overview, comparison tables, and notes sections\n- **Streamlined format**: Simplified parameter descriptions\n- **Consolidated content**: Focused only on essential tool information\n- **Removed examples**: Eliminated verbose usage examples\n\n## \u2705 Quality Assurance\n\n### Evaluation Results\n- **Test cases**: 36 total\n- **Exact matches**: 35/36 (97.2% accuracy)\n- **Tool selection**: 100% accurate\n- **Parameter mapping**: 100% functionally correct\n\n### Single Mismatch Analysis\nThe one mismatch was a **style difference** rather than a functional error:\n- Generated version: More explicit field specifications\n- Gold standard: Minimal field specifications\n- Both approaches are functionally equivalent\n'})}),"\n",(0,s.jsx)(t.h2,{id:"6-conclusion",children:"6. Conclusion"}),"\n",(0,s.jsxs)(t.p,{children:["Automated MCP metadata validation doesn\u2019t have to be brittle or one-off. By using a ",(0,s.jsx)(t.strong,{children:"modular Goose recipe architecture"}),", we\u2019ve shown how a single core prediction recipe can power multiple high-value workflows\u2014from ",(0,s.jsx)(t.strong,{children:"catching regressions early"})," to ",(0,s.jsx)(t.strong,{children:"reducing tokens safely"})," without sacrificing discoverability."]}),"\n",(0,s.jsx)(t.p,{children:"This composable approach offers three big wins:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Reusability"})," \u2013 The same core logic supports different workflows without rewriting code."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Safety"})," \u2013 Automated validation ensures changes never silently break tool usage."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Scalability"})," \u2013 The architecture works across any MCP server or toolset, regardless of size."]}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"With these building blocks in place, teams can confidently expand their automation toolkit\u2014knowing every new optimization or enhancement will be backed by the same rigorous, repeatable validation process."}),"\n",(0,s.jsxs)(a,{children:[(0,s.jsx)("meta",{property:"og:title",content:"Automated MCP Testing: Using Composable Goose Recipes to Validate Tool Metadata"}),(0,s.jsx)("meta",{property:"og:type",content:"article"}),(0,s.jsx)("meta",{property:"og:url",content:"https://block.github.io/goose/blog/2025/08/12/mcp-testing"}),(0,s.jsx)("meta",{property:"og:description",content:"Automate MCP tool metadata validation using composable Goose recipes to catch regressions, optimize token usage, and ensure AI agents can reliably discover and use your tools"}),(0,s.jsx)("meta",{property:"og:image",content:"https://block.github.io/goose/assets/images/automated_mcp_testing-296dac2cd2b1b327e58854f4bfb0c89a.jpg"}),(0,s.jsx)("meta",{name:"twitter:card",content:"summary_large_image"}),(0,s.jsx)("meta",{property:"twitter:domain",content:"block.github.io/goose"}),(0,s.jsx)("meta",{name:"twitter:title",content:"Automated MCP Testing: Using Composable Goose Recipes to Validate Tool Metadata"}),(0,s.jsx)("meta",{name:"twitter:description",content:"Automate MCP tool metadata validation using composable Goose recipes to catch regressions, optimize token usage, and ensure AI agents can reliably discover and use your tools"}),(0,s.jsx)("meta",{name:"twitter:image",content:"https://block.github.io/goose/assets/images/automated_mcp_testing-296dac2cd2b1b327e58854f4bfb0c89a.jpg"})]})]})}function p(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}function u(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}},35151:(e,t,n)=>{n.d(t,{A:()=>o});const o=n.p+"assets/images/automated_mcp_testing-296dac2cd2b1b327e58854f4bfb0c89a.jpg"},38351:(e,t,n)=>{n.d(t,{A:()=>o});const o=n.p+"assets/images/evaluate_predictions-5339152506fc0a0580e88a6257f45af7.png"},84218:(e,t,n)=>{n.d(t,{A:()=>o});const o=n.p+"assets/images/reduce_tokens-038444961b7250c0bcba776d4109702a.png"},28453:(e,t,n)=>{n.d(t,{R:()=>a,x:()=>r});var o=n(96540);const s={},i=o.createContext(s);function a(e){const t=o.useContext(i);return o.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),o.createElement(i.Provider,{value:t},e.children)}},58288:e=>{e.exports=JSON.parse('{"permalink":"/goose/blog/2025/08/12/mcp-testing","source":"@site/blog/2025-08-12-mcp-testing/index.md","title":"Automated MCP Testing: Using Composable Goose Recipes to Validate Tool Metadata","description":"Automate MCP tool metadata validation using composable Goose recipes to catch regressions, optimize token usage, and ensure AI agents can reliably discover and use your tools.","date":"2025-08-12T00:00:00.000Z","tags":[],"readingTime":14.955,"hasTruncateMarker":true,"authors":[{"name":"Ravneet Singh Arora","title":"Staff Machine Learning Engineer","page":{"permalink":"/goose/blog/authors/rarora"},"socials":{"linkedin":"https://www.linkedin.com/in/ravneet-arora-9b913537/","github":"https://github.com/ravarora2"},"imageURL":"https://avatars.githubusercontent.com/u/130506156?v=4","key":"rarora"}],"frontMatter":{"title":"Automated MCP Testing: Using Composable Goose Recipes to Validate Tool Metadata","description":"Automate MCP tool metadata validation using composable Goose recipes to catch regressions, optimize token usage, and ensure AI agents can reliably discover and use your tools.","authors":["rarora"]},"unlisted":false,"prevItem":{"title":"How PulseMCP Automated Their Newsletter Workflow with Goose","permalink":"/goose/blog/2025/08/13/pulse-mcp-automates-recipe"},"nextItem":{"title":"LLM Tag Team: Who Plans, Who Executes?","permalink":"/goose/blog/2025/08/11/llm-tag-team-lead-worker-model"}}')}}]);