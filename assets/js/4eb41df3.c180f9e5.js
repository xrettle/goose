"use strict";(self.webpackChunkgoose=self.webpackChunkgoose||[]).push([[4526],{77503:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>i,metadata:()=>o,toc:()=>c});var o=n(3999),s=n(74848),r=n(28453);const i={title:"MCP Jupyter: AI-Powered Machine Learning and Data Science",description:"Enable AI agents to work directly with your Jupyter notebooks, leveraging persistent memory and stateful collaboration for enhanced ML and data science workflows",date:new Date("2025-08-05T00:00:00.000Z"),authors:["damien","dean","harrison"]},a=void 0,l={authorsImageUrls:[void 0,void 0,void 0]},c=[{value:"The Memory and Context Problem",id:"the-memory-and-context-problem",level:2},{value:"A Better Approach: Persistent State",id:"a-better-approach-persistent-state",level:2},{value:"Transforming ML Workflows",id:"transforming-ml-workflows",level:2},{value:"Exploratory Data Analysis",id:"exploratory-data-analysis",level:3},{value:"Interactive Model Development",id:"interactive-model-development",level:3},{value:"Real-time Debugging",id:"real-time-debugging",level:3},{value:"Continuous Collaboration",id:"continuous-collaboration",level:3},{value:"Example notebook",id:"example-notebook",level:2},{value:"Getting Started",id:"getting-started",level:2}];function d(e){const t={a:"a",blockquote:"blockquote",em:"em",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components},{Head:o}=t;return o||function(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Head",!0),(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"MCP Jupyter Server",src:n(44115).A+"",width:"1200",height:"630"})}),"\n",(0,s.jsx)(t.p,{children:"Machine learning and data science workflows are inherently iterative. You load data, explore patterns, build models, and refine your approach based on results. But traditional AI assistants lose context between interactions, forcing you to reload data and re-establish context repeatedly\u2014making data-heavy development slow and expensive."}),"\n",(0,s.jsxs)(t.p,{children:["The ",(0,s.jsx)(t.a,{href:"https://github.com/block/mcp-jupyter",children:(0,s.jsx)(t.strong,{children:"MCP Jupyter Server"})})," solves this by enabling AI agents like Goose to work directly with your Jupyter notebooks, maintaining persistent memory and state across interactions while letting the AI interact with your data through code execution rather than raw data transfer."]}),"\n",(0,s.jsx)("iframe",{class:"aspect-ratio",src:"https://www.youtube.com/embed/0i6gB_mWaRM",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",referrerpolicy:"strict-origin-when-cross-origin",allowfullscreen:!0}),"\n",(0,s.jsx)(t.h2,{id:"the-memory-and-context-problem",children:"The Memory and Context Problem"}),"\n",(0,s.jsx)(t.p,{children:"Traditional AI coding assistants face a fundamental limitation: they lose context between interactions. This in part stems from their design to accomplish well-described individual tasks like refactoring a piece of code, compiling and running its tests, and commiting the result version control. In contrast, data science workflows are often open-ended and require extensive exploration and interactivity. This creates several challenges for using AI with data-heavy ML workflows:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Constant data reloading"}),": Each interaction requires re-loading or describing your dataset"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Expensive iteration"}),": Large datasets are slow and costly to process repeatedly"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Context size"}),": The raw data may be too large to be fit in context"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Not designed for interactive work"}),": It is harder to have the assistant do some steps and then transfer control back to the human or vice versa"]}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"To address these challenges, we created the MCP Jupyter Server."}),"\n",(0,s.jsx)(t.h2,{id:"a-better-approach-persistent-state",children:"A Better Approach: Persistent State"}),"\n",(0,s.jsx)(t.p,{children:"The MCP Jupyter Server takes a different approach. Instead of losing context between interactions, it maintains persistent memory and lets the AI interact with your data through Jupyter code cell execution. This creates a powerful paradigm:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Persistent memory"}),": Variables and state are maintained across all interactions"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Efficient iterations"}),": No need to reload data or re-establish context"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Code-based data interaction"}),": AI explores data through execution, not given the raw data in context"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"True pair programming"}),": Seamless collaboration within the same notebook context"]}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"transforming-ml-workflows",children:"Transforming ML Workflows"}),"\n",(0,s.jsx)(t.h3,{id:"exploratory-data-analysis",children:"Exploratory Data Analysis"}),"\n",(0,s.jsx)(t.p,{children:"Instead of describing your dataset, let the AI explore it directly:"}),"\n",(0,s.jsxs)(t.blockquote,{children:["\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("span",{style:{color:"#2563eb",fontWeight:"bold"},children:"User:"}),' "Help me understand this customer dataset"']}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("span",{style:{color:"#059669",fontWeight:"bold"},children:"AI:"}),' "Let me explore your data structure first"']}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.em,{children:(0,s.jsx)("span",{style:{color:"#6b7280",fontStyle:"italic"},children:"[AI executes: df.info(), df.describe(), df.head()]"})})}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("span",{style:{color:"#059669",fontWeight:"bold"},children:"AI:"})," \"I can see you have 50,000 customers with 12 features. The data includes demographics (age, income), behavioral metrics (purchase_frequency, avg_order_value), and some missing values in the 'phone_number' column. Would you like me to create visualizations for the key relationships, like age vs income or purchase patterns?\""]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("span",{style:{color:"#2563eb",fontWeight:"bold"},children:"User:"}),' "Yes, show me the age and income distributions, and any correlations"']}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("span",{style:{color:"#059669",fontWeight:"bold"},children:"AI:"}),' "Perfect! I\'ll create histograms for age and income, plus a correlation heatmap"']}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.em,{children:(0,s.jsx)("span",{style:{color:"#6b7280",fontStyle:"italic"},children:"[AI generates and displays visualizations]"})})}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"The AI can see your actual column names, data types, and distributions\u2014leading to much more relevant suggestions."}),"\n",(0,s.jsx)(t.h3,{id:"interactive-model-development",children:"Interactive Model Development"}),"\n",(0,s.jsx)(t.p,{children:"The AI becomes a true collaborator in your modeling process:"}),"\n",(0,s.jsxs)(t.blockquote,{children:["\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("span",{style:{color:"#2563eb",fontWeight:"bold"},children:"User:"}),' "This model isn\'t performing well"']}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("span",{style:{color:"#059669",fontWeight:"bold"},children:"AI:"}),' "Let me check the current metrics and feature importance"']}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.em,{children:(0,s.jsx)("span",{style:{color:"#6b7280",fontStyle:"italic"},children:"[AI executes your existing model evaluation code]"})})}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("span",{style:{color:"#059669",fontWeight:"bold"},children:"AI:"})," \"I see the accuracy is 72% and the most important features are 'price' and 'location'. The model seems to be overfitting - would you like me to try regularization or reduce the feature set?\""]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("span",{style:{color:"#2563eb",fontWeight:"bold"},children:"User:"}),' "Try regularization first"']}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("span",{style:{color:"#059669",fontWeight:"bold"},children:"AI:"}),' "I\'ll add L2 regularization and test different alpha values"']}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.em,{children:(0,s.jsx)("span",{style:{color:"#6b7280",fontStyle:"italic"},children:"[AI implements and tests changes iteratively]"})})}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("span",{style:{color:"#059669",fontWeight:"bold"},children:"AI:"}),' "Great! With alpha=0.1, accuracy improved to 78% and the validation curve looks much better. Should I tune it further or try ensemble methods?"']}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"real-time-debugging",children:"Real-time Debugging"}),"\n",(0,s.jsx)(t.p,{children:"When errors occur, the assistant has full context:"}),"\n",(0,s.jsxs)(t.blockquote,{children:["\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("span",{style:{color:"#2563eb",fontWeight:"bold"},children:"User:"}),' "I\'m getting a KeyError in cell 5"']}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("span",{style:{color:"#059669",fontWeight:"bold"},children:"AI:"}),' "Let me check what columns are available in your dataframe"']}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.em,{children:(0,s.jsx)("span",{style:{color:"#6b7280",fontStyle:"italic"},children:"[AI executes: df.columns, df.info()]"})})}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("span",{style:{color:"#059669",fontWeight:"bold"},children:"AI:"})," \"I see the issue - you're trying to access 'customer_id' but the actual column name is 'CustomerID' with capital letters. Also, I notice you have 'purchase_date' as a string - should I convert that to datetime while I fix the KeyError?\""]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("span",{style:{color:"#2563eb",fontWeight:"bold"},children:"User:"}),' "Yes, fix both issues"']}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("span",{style:{color:"#059669",fontWeight:"bold"},children:"AI:"}),' "Done! I\'ve updated the column reference and converted purchase_date to datetime. The cell should run properly now."']}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"continuous-collaboration",children:"Continuous Collaboration"}),"\n",(0,s.jsx)(t.p,{children:"Imagine a scenario where you are working on a new dataset:"}),"\n",(0,s.jsxs)(t.blockquote,{children:["\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("span",{style:{color:"#2563eb",fontWeight:"bold"},children:"User:"})," ",(0,s.jsx)(t.em,{children:(0,s.jsx)("span",{style:{color:"#6b7280",fontStyle:"italic"},children:"[Executes: df = pd.read_csv('sales_data.csv')]"})})]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("span",{style:{color:"#2563eb",fontWeight:"bold"},children:"User:"}),' "Let me check the data types and look for any anomalies"']}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("span",{style:{color:"#059669",fontWeight:"bold"},children:"AI:"}),' "I\'ll analyze your sales data structure"']}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.em,{children:(0,s.jsx)("span",{style:{color:"#6b7280",fontStyle:"italic"},children:"[AI executes: df.info(), df.describe(include='all')]"})})}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("span",{style:{color:"#059669",fontWeight:"bold"},children:"AI:"})," \"I found a few issues: 'CustomerID' is stored as text but should be numeric, and there are 847 missing values in 'SalesAmount'. Would you like me to convert 'CustomerID' to numeric and fill the missing 'SalesAmount' values with the median?\""]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("span",{style:{color:"#2563eb",fontWeight:"bold"},children:"User:"}),' "Yes, please do that and show me the updated info"']}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("span",{style:{color:"#059669",fontWeight:"bold"},children:"AI:"}),' "Done! CustomerID is now numeric and SalesAmount gaps are filled. Your dataset is clean and ready for modeling."']}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.em,{children:(0,s.jsx)("span",{style:{color:"#6b7280",fontStyle:"italic"},children:"[Later in the session, after you've trained a model...]"})})}),"\n",(0,s.jsxs)(t.blockquote,{children:["\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("span",{style:{color:"#2563eb",fontWeight:"bold"},children:"User:"}),' "How is my model performing?"']}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("span",{style:{color:"#059669",fontWeight:"bold"},children:"AI:"}),' "Let me generate the key metrics for your trained model"']}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.em,{children:(0,s.jsx)("span",{style:{color:"#6b7280",fontStyle:"italic"},children:"[AI accesses the existing model variable and generates evaluation metrics]"})})}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)("span",{style:{color:"#059669",fontWeight:"bold"},children:"AI:"}),' "Your Random Forest achieved 0.84 precision and 0.81 recall. The confusion matrix shows some false positives in the high-value sales category. Would you like me to adjust the decision threshold or try feature engineering?"']}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"This fluid back-and-forth, where the assistant understands and builds upon the existing notebook state, allows for seamless collaboration without the need for constant context re-establishment or data reloading."}),"\n",(0,s.jsx)(t.h2,{id:"example-notebook",children:"Example notebook"}),"\n",(0,s.jsx)(t.p,{children:"Here you can see an example notebook that was handled by the MCP Jupyter Server.  The server"}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:(0,s.jsx)(t.a,{href:"https://github.com/block/mcp-jupyter/blob/main/demos/demo.ipynb",children:"\ud83d\udcd3 View the Complete Demo Notebook"})})}),"\n",(0,s.jsx)(t.p,{children:"The demo walks through a typical data science workflow:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Install Missing Libraries"}),": Installing missing libraries for the notebook"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Data Generation"}),": Creating synthetic data for analysis"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Model Training"}),": Fitting a linear regression model with scikit-learn"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Results Analysis"}),": Extracting model coefficients and performance metrics"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Visualization"}),": Creating plots with seaborn"]}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"getting-started",children:"Getting Started"}),"\n",(0,s.jsx)(t.p,{children:"The MCP Jupyter Server integrates seamlessly with existing workflows and can also be used with the notebook viewer in VS Code based IDEs."}),"\n",(0,s.jsxs)(t.p,{children:["For detailed setup and configuration, check out the ",(0,s.jsx)(t.a,{href:"https://block.github.io/mcp-jupyter/",children:"complete documentation"}),"."]}),"\n",(0,s.jsxs)(o,{children:[(0,s.jsx)("meta",{property:"og:title",content:"MCP Jupyter Server: Bringing Notebook Intelligence to AI Agents"}),(0,s.jsx)("meta",{property:"og:type",content:"article"}),(0,s.jsx)("meta",{property:"og:url",content:"https://block.github.io/goose/blog/2025/06/24/mcp-jupyter-server"}),(0,s.jsx)("meta",{property:"og:description",content:"A powerful MCP server that enables AI agents to interact with Jupyter notebooks while preserving kernel state and variable context"}),(0,s.jsx)("meta",{property:"og:image",content:"https://block.github.io/goose/assets/images/data-goose-7fc60ab0a13a9e9b6c22172d6ac166ab.png"}),(0,s.jsx)("meta",{name:"twitter:card",content:"summary_large_image"}),(0,s.jsx)("meta",{property:"twitter:domain",content:"block.github.io/goose"}),(0,s.jsx)("meta",{name:"twitter:title",content:"MCP Jupyter Server: Bringing Notebook Intelligence to AI Agents"}),(0,s.jsx)("meta",{name:"twitter:description",content:"A powerful MCP server that enables AI agents to interact with Jupyter notebooks while preserving kernel state and variable context"}),(0,s.jsx)("meta",{name:"twitter:image",content:"https://block.github.io/goose/assets/images/data-goose-7fc60ab0a13a9e9b6c22172d6ac166ab.png"})]})]})}function h(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},44115:(e,t,n)=>{n.d(t,{A:()=>o});const o=n.p+"assets/images/data-goose-7fc60ab0a13a9e9b6c22172d6ac166ab.png"},28453:(e,t,n)=>{n.d(t,{R:()=>i,x:()=>a});var o=n(96540);const s={},r=o.createContext(s);function i(e){const t=o.useContext(r);return o.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),o.createElement(r.Provider,{value:t},e.children)}},3999:e=>{e.exports=JSON.parse('{"permalink":"/goose/blog/2025/08/04/mcp-jupyter-server","source":"@site/blog/2025-08-04-mcp-jupyter-server/index.md","title":"MCP Jupyter: AI-Powered Machine Learning and Data Science","description":"Enable AI agents to work directly with your Jupyter notebooks, leveraging persistent memory and stateful collaboration for enhanced ML and data science workflows","date":"2025-08-05T00:00:00.000Z","tags":[],"readingTime":6.56,"hasTruncateMarker":true,"authors":[{"name":"Damien Ramunno-Johnson","title":"Principal Machine Learning Engineer","page":{"permalink":"/goose/blog/authors/damien"},"socials":{"linkedin":"https://www.linkedin.com/in/damienrj/","github":"https://github.com/damienrj"},"imageURL":"https://avatars.githubusercontent.com/u/2729283?v=4","key":"damien"},{"name":"Dean Wyatte","title":"Principal Machine Learning Engineer","page":{"permalink":"/goose/blog/authors/dean"},"socials":{"github":"https://github.com/dwyatte"},"imageURL":"https://avatars.githubusercontent.com/u/2512762?v=4","key":"dean"},{"name":"Harrison Mamin","title":"Senior Machine Learning Engineer","page":{"permalink":"/goose/blog/authors/harrison"},"socials":{"github":"https://github.com/hdmamin"},"imageURL":"https://avatars.githubusercontent.com/u/114013937?v=4","key":"harrison"}],"frontMatter":{"title":"MCP Jupyter: AI-Powered Machine Learning and Data Science","description":"Enable AI agents to work directly with your Jupyter notebooks, leveraging persistent memory and stateful collaboration for enhanced ML and data science workflows","date":"2025-08-05T00:00:00.000Z","authors":["damien","dean","harrison"]},"unlisted":false,"prevItem":{"title":"How 7 AI Agents Worked Together to Build an App in One Hour","permalink":"/goose/blog/2025/08/10/vibe-coding-with-goose-building-apps-with-ai-agents"},"nextItem":{"title":"How OpenRouter Unlocked Our Workshop Strategy","permalink":"/goose/blog/2025/07/29/openrouter-unlocks-workshops"}}')}}]);